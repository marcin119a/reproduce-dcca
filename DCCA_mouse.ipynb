{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68768166-bca8-4410-b3f5-e6501e545d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce5c86a-e355-4f44-8aea-2005b0dfce13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cca = CCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752782d9-a20f-4cbd-9023-eacce071f418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "X = pd.read_csv('Wild-type.csv', index_col=0)[:13509]\n",
    "Y = pd.read_csv('DUSP6-KO.csv', index_col=0)[:13509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefc24f5-2003-4d0b-b886-cfd5e57ff568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "Y = pd.read_csv('test1_scaled.csv').to_numpy()\n",
    "X = pd.read_csv('test2_scaled.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7035e24d-78ff-447c-893b-ada441392bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc49d81-d653-44b8-833d-128a0c7d5b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4b89a-3a20-46a9-8b26-8b706c7d33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cce80f0-406f-4224-8ed4-ac954a87cda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as T\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class DCCA(Layer):\n",
    "    '''CCA layer is used compute the CCA objective\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as the input.\n",
    "\n",
    "    # Arguments\n",
    "        output_dim: output dimension, default 1, i.e., correlation coefficient\n",
    "        use_all_singular_value: if use the top-k singular values\n",
    "        cca_space_dim: the number of singular values, i.e., k\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, output_dim=1, use_all_singular_values=True, cca_space_dim=10, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.cca_space_dim = cca_space_dim\n",
    "        self.use_all_singular_values = use_all_singular_values\n",
    "        super(DCCA, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        super(DCCA, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        r1 = tf.constant([1e-4])\n",
    "        r2 = tf.constant([1e-4])\n",
    "        eps = tf.constant([1e-12])\n",
    "        o1 = o2 = tf.shape(x)[1] // 2\n",
    "\n",
    "        H1 = T.transpose(x[:, 0:o1])\n",
    "        H2 = T.transpose(x[:, o1:o1 + o2])\n",
    "\n",
    "        one = tf.constant([1.0])\n",
    "        m = tf.shape(H1)[1]\n",
    "        m_float = tf.cast(m, 'float')\n",
    "\n",
    "        # minus the mean value\n",
    "        partition = tf.divide(one, m_float)\n",
    "        H1bar = H1 - partition * tf.matmul(H1, tf.ones([m, m]))\n",
    "        H2bar = H2 - partition * tf.matmul(H2, tf.ones([m, m]))\n",
    "\n",
    "        # calculate the auto-covariance and cross-covariance\n",
    "        partition2 = tf.divide(one, (m_float - 1))\n",
    "        SigmaHat12 = partition2 * tf.matmul(H1bar, tf.transpose(H2bar))\n",
    "        SigmaHat11 = partition2 * tf.matmul(H1bar, tf.transpose(H1bar)) + r1 * tf.eye(o1)\n",
    "        SigmaHat22 = partition2 * tf.matmul(H2bar, tf.transpose(H2bar)) + r2 * tf.eye(o2)\n",
    "\n",
    "        # calculate the root inverse of covariance matrices by using eigen decomposition\n",
    "        D1, V1 = tf.linalg.eigh(SigmaHat11)\n",
    "        D2, V2 = tf.linalg.eigh(SigmaHat22)\n",
    "\n",
    "        # for stability\n",
    "        D1_indices = tf.where(D1 > eps)\n",
    "        D1_indices = tf.squeeze(D1_indices)\n",
    "        V1 = tf.gather(V1, D1_indices)\n",
    "        D1 = tf.gather(D1, D1_indices)\n",
    "\n",
    "        D2_indices = tf.where(D2 > eps)\n",
    "        D2_indices = tf.squeeze(D2_indices)\n",
    "        V2 = tf.gather(V2, D2_indices)\n",
    "        D2 = tf.gather(D2, D2_indices)\n",
    "\n",
    "        pow_value = tf.constant([-0.5])\n",
    "        SigmaHat11RootInv = tf.matmul(tf.matmul(V1, tf.linalg.diag(tf.pow(D1, pow_value))), tf.transpose(V1))\n",
    "        SigmaHat22RootInv = tf.matmul(tf.matmul(V2, tf.linalg.diag(tf.pow(D2, pow_value))), tf.transpose(V2))\n",
    "\n",
    "        Tval = tf.matmul(tf.matmul(SigmaHat11RootInv, SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "        if self.use_all_singular_values:\n",
    "            # all singular values are used to calculate the correlation\n",
    "            corr = tf.linalg.trace(T.sqrt(tf.matmul(tf.transpose(Tval), Tval)))\n",
    "        else:\n",
    "            # just the top outdim_size singular values are used\n",
    "            TT = tf.matmul(tf.transpose(Tval), Tval)\n",
    "            U, V = tf.raw_ops.SelfAdjointEigV2(input=TT)\n",
    "            U_sort, _ = tf.nn.top_k(U, self.cca_space_dim)\n",
    "            corr = T.sum(T.sqrt(U_sort))\n",
    "\n",
    "        corr = tf.fill([tf.shape(x)[0], self.output_dim], corr)\n",
    "\n",
    "        return -corr\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'cca_dim': self.cca_dim,\n",
    "            'use_all_singular_values': self.use_all_singular_values,\n",
    "        }\n",
    "        base_config = super(CCA, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16ca62b1-1d3d-4791-9b45-29b71ea9563b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class LogNormalizeLayer(Layer):\n",
    "    def __init__(self, scale_factor=10000):\n",
    "        super(LogNormalizeLayer, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Obliczanie sumy wartości dla każdej komórki\n",
    "        total_counts = tf.reduce_sum(inputs, axis=-1, keepdims=True)\n",
    "\n",
    "        # Normalizacja danych przez podzielenie przez sumę\n",
    "        normalized_data = tf.divide(inputs, total_counts)\n",
    "\n",
    "        # Przekształcenie logarytmiczne danych z uwzględnieniem skali i dodaniem 1\n",
    "        log_transformed_data = tf.math.log(self.scale_factor * normalized_data + 1)\n",
    "\n",
    "        return log_transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bab3815b-5e70-4529-985f-835c2f981adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 29ms/step - loss: -4.5911 - mean_pred: -4.5911\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: -9.7784 - mean_pred: -9.7784\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: -12.8094 - mean_pred: -12.8094\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: -14.9918 - mean_pred: -14.9918\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -16.7082 - mean_pred: -16.7082\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -18.1183 - mean_pred: -18.1183\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: -19.2857 - mean_pred: -19.2857\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: -20.2811 - mean_pred: -20.2811\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -21.0997 - mean_pred: -21.0997\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -21.7829 - mean_pred: -21.7829\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -22.3404 - mean_pred: -22.3404\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -22.7864 - mean_pred: -22.7864\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -23.1551 - mean_pred: -23.1551\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -23.4557 - mean_pred: -23.4557\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -23.7085 - mean_pred: -23.7085\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -23.9241 - mean_pred: -23.9241\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -24.1066 - mean_pred: -24.1066\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.2638 - mean_pred: -24.2638\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.3971 - mean_pred: -24.3971\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.5125 - mean_pred: -24.5125\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.6079 - mean_pred: -24.6079\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.6913 - mean_pred: -24.6913\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.7569 - mean_pred: -24.7569\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.8107 - mean_pred: -24.8107\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.8550 - mean_pred: -24.8550\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.8856 - mean_pred: -24.8856\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9086 - mean_pred: -24.9086\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9247 - mean_pred: -24.9247\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9347 - mean_pred: -24.9347\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9408 - mean_pred: -24.9408\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9445 - mean_pred: -24.9445\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9477 - mean_pred: -24.9477\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9490 - mean_pred: -24.9490\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9437 - mean_pred: -24.9437\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9475 - mean_pred: -24.9475\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9496 - mean_pred: -24.9496\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9497 - mean_pred: -24.9497\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9500 - mean_pred: -24.9500\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9492 - mean_pred: -24.9492\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9479 - mean_pred: -24.9479\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -24.9488 - mean_pred: -24.9488\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9515 - mean_pred: -24.9515\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9522 - mean_pred: -24.9522\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9522 - mean_pred: -24.9522\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9512 - mean_pred: -24.9512\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9516 - mean_pred: -24.9516\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9506 - mean_pred: -24.9506\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9519 - mean_pred: -24.9519\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -24.9515 - mean_pred: -24.9515\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -24.9544 - mean_pred: -24.9544\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9535 - mean_pred: -24.9535\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: -24.9549 - mean_pred: -24.9549\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: -24.9544 - mean_pred: -24.9544\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: -24.9519 - mean_pred: -24.9519\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9525 - mean_pred: -24.9525\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9552 - mean_pred: -24.9552\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9566 - mean_pred: -24.9566\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9545 - mean_pred: -24.9545\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9531 - mean_pred: -24.9531\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -24.9545 - mean_pred: -24.9545\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9560 - mean_pred: -24.9560\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9554 - mean_pred: -24.9554\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9565 - mean_pred: -24.9565\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9553 - mean_pred: -24.9553\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9579 - mean_pred: -24.9579\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9580 - mean_pred: -24.9580\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9577 - mean_pred: -24.9577\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9562 - mean_pred: -24.9562\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9573 - mean_pred: -24.9573\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9579 - mean_pred: -24.9579\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9570 - mean_pred: -24.9570\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9578 - mean_pred: -24.9578\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9584 - mean_pred: -24.9584\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9588 - mean_pred: -24.9588\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9583 - mean_pred: -24.9583\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9577 - mean_pred: -24.9577\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9589 - mean_pred: -24.9589\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9594 - mean_pred: -24.9594\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9611 - mean_pred: -24.9611\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9602 - mean_pred: -24.9602\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9591 - mean_pred: -24.9591\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9600 - mean_pred: -24.9600\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9601 - mean_pred: -24.9601\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9606 - mean_pred: -24.9606\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9600 - mean_pred: -24.9600\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9606 - mean_pred: -24.9606\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9606 - mean_pred: -24.9606\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: -24.9623 - mean_pred: -24.9623\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: -24.9619 - mean_pred: -24.9619\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9624 - mean_pred: -24.9624\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9609 - mean_pred: -24.9609\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9630 - mean_pred: -24.9630\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9622 - mean_pred: -24.9622\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9621 - mean_pred: -24.9621\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9618 - mean_pred: -24.9618\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9620 - mean_pred: -24.9620\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9631 - mean_pred: -24.9631\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9622 - mean_pred: -24.9622\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: -24.9617 - mean_pred: -24.9617\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: -24.9637 - mean_pred: -24.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc90c70ded0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def constant_loss(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "#train_set_x1, valid_set_x1, train_set_x2, valid_set_x2 = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 2000\n",
    "input_shape2 = 2000\n",
    "\n",
    "# network settings\n",
    "epoch_num = 100\n",
    "\n",
    "\n",
    "batch_size = 2000\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "#load data\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "input1 = Input(shape=(input_shape1, ), name='input1')\n",
    "input2 = Input(shape=(input_shape2, ), name='input2')\n",
    "\n",
    "expert_index = 0\n",
    "# Definicja funkcji aktywacji\n",
    "activation_model = LeakyReLU(alpha=0.2)\n",
    "\n",
    "# Warstwy wejściowe\n",
    "input1 = Input(shape=(input_shape1,))\n",
    "input2 = Input(shape=(input_shape2,))\n",
    "\n",
    "# Warstwy gęste dla widoku 1\n",
    "normalizaction_1 = BatchNormalization()(input1)\n",
    "dense1_1 = Dense(1024, activation=activation_model, name='view_1_1')(normalizaction_1)\n",
    "dense1_2 = Dense(512, activation=activation_model, name='view_1_2')(dense1_1)\n",
    "dense1_3 = Dense(256, activation=activation_model, name='view_1_3')(dense1_2)\n",
    "output1 = Dense(25, activation='linear', name='view_1_4')(dense1_3)\n",
    "\n",
    "# Warstwy gęste dla widoku 2\n",
    "normalizaction_2 = BatchNormalization()(input1)\n",
    "dense2_1 = Dense(1024, activation=activation_model, name='view_2_1')(normalizaction_2)\n",
    "dense2_2 = Dense(512, activation=activation_model, name='view_2_2')(dense2_1)\n",
    "dense2_3 = Dense(256, activation=activation_model, name='view_2_3')(dense2_2)\n",
    "output2 = Dense(25, activation='linear', name='view_2_4')(dense2_3)\n",
    "\n",
    "# Warstwa łącząca\n",
    "shared_layer = concatenate([output1, output2], name='shared_layer')\n",
    "\n",
    "# Normalizacja danych\n",
    "shared_layer = BatchNormalization()(shared_layer)\n",
    "\n",
    "cca_layer = DCCA(1, name='cca_layer')(shared_layer)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=cca_layer)\n",
    "model.compile(optimizer=RMSprop(lr=0.0001), loss=constant_loss, metrics=[mean_pred])\n",
    "model.fit([X, Y], np.zeros(len(X)),\n",
    "          batch_size=batch_size, epochs=epoch_num, shuffle=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "560f0dca-a1c1-42c0-a592-368624596e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# evaluation for view_1\n",
    "current_dcca = Model(model.input, model.get_layer(name='shared_layer').output)\n",
    "\n",
    "\n",
    "pred_out = current_dcca.predict([X, Y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6feb2c97-a217-4b80-8095-9b445f2d1586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c86fa95-f4b7-4cbb-be41-888f4a856ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "\n",
    "import numpy\n",
    "def total_correlation(X1, X2, k):\n",
    "    r1 = 1e-4\n",
    "    r2 = 1e-4\n",
    "\n",
    "    n1 = X1.shape[1]\n",
    "    n2 = X2.shape[1]\n",
    "    m = X1.shape[0] #number of rows\n",
    "\n",
    "    mean1 = numpy.mean(X1, axis=0)\n",
    "    mean2 = numpy.mean(X2, axis=0)\n",
    "\n",
    "    H1bar = X1 - numpy.tile(mean1, (m, 1))\n",
    "    H2bar = X2 - numpy.tile(mean2, (m, 1))\n",
    "\n",
    "\n",
    "    SigmaHat12 = (1.0 / (m - 1)) * numpy.dot(H1bar.T, H2bar) # cross-covariance matrix\n",
    "    SigmaHat11 = (1.0 / (m - 1)) * numpy.dot(H1bar.T, H1bar) + r1 * numpy.identity(n1) # covariances\n",
    "    SigmaHat22 = (1.0 / (m - 1)) * numpy.dot(H2bar.T, H2bar) + r2 * numpy.identity(n2) # covariances\n",
    "\n",
    "\n",
    "    [D1, V1] = numpy.linalg.eigh(SigmaHat11) #Eigendecomposition for easy inversion\n",
    "    [D2, V2] = numpy.linalg.eigh(SigmaHat22) #Eigendecomposition for easy inversion\n",
    "    SigmaHat11RootInv = numpy.dot(numpy.dot(V1, numpy.diag(D1 ** -0.5)), V1.T) #\n",
    "    SigmaHat22RootInv = numpy.dot(numpy.dot(V2, numpy.diag(D2 ** -0.5)), V2.T)\n",
    "    T = numpy.dot(numpy.dot(SigmaHat11RootInv, SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "\n",
    "    [U, D, V] = numpy.linalg.svd(T)\n",
    "    V = V.T\n",
    "    Astar = numpy.dot(SigmaHat11RootInv, U[:, 0:k])\n",
    "    Bstar = numpy.dot(SigmaHat22RootInv, V[:, 0:k])\n",
    "    D = D[0:k]\n",
    "\n",
    "    top_k_singular_values = D[:k]\n",
    "\n",
    "    total_corr = numpy.sum(D)\n",
    "\n",
    "    return Astar, total_corr, top_k_singular_values, Bstar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fbea01c-7a0d-419e-91f8-a6e3e8a7418c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.65225721257287"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, total_corr, singular_values, V = total_correlation(X, Y, k=25)\n",
    "total_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf51094-4aaf-4132-9780-ccb5b7967bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
